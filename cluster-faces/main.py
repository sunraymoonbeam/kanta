# src/main.py
"""Entry point for clustering face embeddings using Hydra with preprocessing."""

import ast
import asyncio
import os
from datetime import datetime, timezone
from typing import Any, List, Tuple

import hydra
import numpy as np
from dotenv import load_dotenv
from loguru import logger
from omegaconf import DictConfig
from sklearn.preprocessing import normalize
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from src.clustering import (
    affinity_propagation_cluster,
    agglomerative_cluster,
    birch_cluster,
    chinese_whispers_cluster,
    dbscan_cluster,
    hdbscan_cluster,
    optics_cluster,
)
from src.processing import process_pca, process_umap
from tqdm.asyncio import tqdm
from omegaconf import OmegaConf

# Load environment variables
load_dotenv()

# Async DB session setup
POSTGRES_URI = (
    f"postgresql+asyncpg://{os.getenv('POSTGRES_USER')}:"
    f"{os.getenv('POSTGRES_PASSWORD')}@"
    f"{os.getenv('POSTGRES_SERVER')}/"
    f"{os.getenv('POSTGRES_DB')}"
)
engine = create_async_engine(POSTGRES_URI, echo=False)
AsyncSessionLocal = sessionmaker(
    bind=engine, class_=AsyncSession, expire_on_commit=False
)


async def get_running_events(session: AsyncSession) -> List[int]:
    """Fetch IDs of events that havenâ€™t ended yet."""
    now = datetime.now(timezone.utc)
    query = text("SELECT id FROM events WHERE end_date_time >= :now")
    result = await session.execute(query, {"now": now})
    event_ids = [row[0] for row in result.fetchall()]
    return event_ids


async def has_unclustered_faces(session: AsyncSession, event_id: int) -> bool:
    """
    Check if an event has any unclustered faces (cluster_id = -2).

    Args:
        session: Async DB session.
        event_id: Event ID.

    Returns:
        True if there are unclustered faces, False otherwise.
    """
    query = text("SELECT COUNT(*) FROM faces WHERE event_id = :event_id AND cluster_id = -2")
    result = await session.execute(query, {"event_id": event_id})
    count = result.scalar()
    return count > 0


async def get_embeddings(session: AsyncSession, event_id: int) -> List[Tuple[int, Any]]:
    """
    Fetch ALL face embeddings for a given event.

    Args:
        session: Async DB session.
        event_id: Event ID.

    Returns:
        List of tuples (face_id, embedding).
    """
    query = text("SELECT id, embedding " "FROM faces " "WHERE event_id = :event_id")
    result = await session.execute(query, {"event_id": event_id})
    rows = result.fetchall()
    return rows


async def update_clusters(
    session: AsyncSession, face_ids: List[int], cluster_labels: np.ndarray
) -> None:
    """
    Update faces with new cluster IDs.

    Args:
        session: Async DB session.
        face_ids: List of face IDs.
        cluster_labels: Array of cluster labels.
    """
    for face_id, cluster_id in zip(face_ids, cluster_labels):
        await session.execute(
            text("UPDATE faces SET cluster_id = :cluster_id WHERE id = :face_id"),
            {"cluster_id": int(cluster_id), "face_id": face_id},
        )
    await session.commit()


async def run(cfg: DictConfig) -> None:
    """
    Main logic: retrieve events, preprocess embeddings, run clustering, and update DB.

    Args:
        cfg: Hydra configuration.
    """
    logger.info("Starting clustering...")

    async with AsyncSessionLocal() as session:
        event_ids = await get_running_events(session)
        logger.info(f"Found {len(event_ids)} running events")

        for event_id in tqdm(event_ids, desc="Processing events"):
            # First check if there are any unclustered faces
            if not await has_unclustered_faces(session, event_id):
                logger.info(f"Skipping event {event_id}: no unclustered faces found")
                continue
            
            # If there are unclustered faces, get ALL faces for clustering
            rows = await get_embeddings(session, event_id)
            face_ids = [r[0] for r in rows]
            count = len(face_ids)

            if count < 2:  # at least 2 faces are required for clustering
                logger.warning(f"Skipping event {event_id}: only {count} face(s)")
                continue
            else:
                logger.info(
                    f"Event {event_id} has {count} face(s), proceeding with clustering"
                )

            # Raw embeddings
            embeddings = np.array(
                [
                    ast.literal_eval(r[1]) if isinstance(r[1], str) else r[1]
                    for r in rows
                ],
                dtype=np.float32,
            )

            # Preprocessing
            if cfg.algo != "chinese_whispers":
                logger.info(
                    f"Preprocessing embeddings with method: '{cfg.processing_method}'"
                )
                if cfg.processing_method == "normalize":
                    embeddings = normalize(embeddings, axis=1)

                elif cfg.processing_method == "pca":
                    embeddings = process_pca(
                        embeddings,
                        n_components=cfg.pca.n_components,
                        whiten=cfg.pca.whiten,
                        random_state=cfg.pca.random_state,
                    )

                elif cfg.processing_method == "umap":
                    embeddings = process_umap(
                        embeddings,
                        n_components=cfg.umap.n_components,
                        n_neighbors=cfg.umap.n_neighbors,
                        min_dist=cfg.umap.min_dist,
                        metric=cfg.umap.metric,
                        random_state=cfg.umap.random_state,
                    )
                logger.info("Sucessfully preprocessed embeddings!")

            try:
                logger.info(
                    f"Performing '{cfg.algo}' clustering on event {event_id}..."
                )
                if cfg.algo == "dbscan":
                    labels = dbscan_cluster(
                        embeddings,
                        eps=cfg.dbscan.eps,
                        min_samples=cfg.dbscan.min_samples,
                        metric=cfg.dbscan.metric,
                        n_jobs=cfg.dbscan.n_jobs,
                    )
                elif cfg.algo == "hdbscan":
                    labels = hdbscan_cluster(
                        embeddings,
                        min_cluster_size=cfg.hdbscan.min_cluster_size,
                        cluster_selection_method=cfg.hdbscan.cluster_selection_method,
                        cluster_selection_epsilon=cfg.hdbscan.cluster_selection_epsilon,
                        alpha=cfg.hdbscan.alpha,
                        metric=cfg.hdbscan.metric,
                    )
                elif cfg.algo == "optics":
                    labels = optics_cluster(
                        embeddings,
                        min_samples=cfg.optics.min_samples,
                        xi=cfg.optics.xi,
                        min_cluster_size=cfg.optics.min_cluster_size,
                        metric=cfg.optics.metric,
                    )
                elif cfg.algo == "affinity_propagation":
                    labels = affinity_propagation_cluster(
                        embeddings,
                        damping=cfg.affinity_propagation.damping,
                        max_iter=cfg.affinity_propagation.max_iter,
                        convergence_iter=cfg.affinity_propagation.convergence_iter,
                    )
                elif cfg.algo == "chinese_whispers":
                    labels = chinese_whispers_cluster(
                        embeddings,
                        threshold=cfg.chinese_whispers.threshold,
                        weighting=cfg.chinese_whispers.weighting,
                    )
                elif cfg.algo == "agglomerative":
                    labels = agglomerative_cluster(
                        embeddings,
                        n_clusters=cfg.agglomerative.n_clusters,
                        distance_threshold=cfg.agglomerative.distance_threshold,
                        linkage=cfg.agglomerative.linkage,
                        metric=cfg.agglomerative.metric,
                    )
                elif cfg.algo == "birch":
                    labels = birch_cluster(
                        embeddings,
                        threshold=cfg.birch.threshold,
                        branching_factor=cfg.birch.branching_factor,
                        n_clusters=cfg.birch.n_clusters,
                    )
                else:
                    raise ValueError(f"Unknown algorithm: {cfg.algo}")
            except Exception as exc:
                logger.error(
                    f"Clustering failed for event {event_id} using '{cfg.algo}': {exc}"
                )
                continue
            n_clusters = len(set(labels.tolist()) - {-1})
            logger.info(
                f"Clustering completed for event {event_id}, found {len(set(labels))} clusters"
            )

            logger.info(f"Updating clusters in database for event {event_id}...")
            await update_clusters(session, face_ids, labels)
            logger.info(
                f"Updated {len(face_ids)} faces with {n_clusters} clusters for event {event_id}"
            )

    logger.info("Clustering run complete.")


@hydra.main(config_path="conf", config_name="config")
def main(cfg: DictConfig) -> None:
    """Hydra main entry point."""
    asyncio.run(run(cfg))

# AWS Lambda handler
async def handler_async(event, context):
    config_path = os.getenv("CONFIG_PATH", "conf/config.yaml")
    cfg = OmegaConf.load(config_path)
    await run(cfg)


def handler(event, context):
    return asyncio.get_event_loop().run_until_complete(handler_async(event, context))


if __name__ == "__main__":
    main()
